defaults:
  resources:
    instance-type: A5000

on:
  github:
    branches:
      only: main
jobs:
  CloneRepo:
    outputs:
      repo:
        type: volume
    uses: git-checkout@v1
    with:
      url: context.event.github.url
  GetFairFaceDataset:
    outputs:
      fair-face-volume:
        type: volume
    uses: script@v1
    with:
      script: |-
        echo "-------------------------------------- 1"
        pip install --upgrade pip setuptools wheel
        pip install kaggle
        echo "-------------------------------------- 2"
        kaggle datasets download -d ghaidaalatoum/fairface -p /outputs/fair-face-volume/ --unzip 
        echo "-------------------------------------- 3"
        ls  /outputs/fair-face-volume/
        echo "-------------------------------------- 4"
      image: tensorflow/tensorflow:2.12.0-gpu

  TrainEightLayersThreeKernelSize:
    needs:
      - CloneRepo
      - GetFairFaceDataset
    inputs:
      repo: CloneRepo.outputs.repo
      fair-face-volume: GetFairFaceDataset.outputs.fair-face-volume
    uses: script@v1
    with:
      script: |-
        echo "-------------------------------------- 0 - List Training Data"
        ls /inputs/fair-face-volume/fairface/
        echo "-------------------------------------- 2 - Access Repo" 
        cd /inputs/repo
        echo "-------------------------------------- 1 - Setup ENV"
        source setup.sh
        echo "-------------------------------------- 3 - Run Training"
        python ./train.py -e 4 -b 64 -s 3 -c 1 --overwrite_sample_number true --number_samples 100 -m ./layers_8_kernel_3_no_flat.yaml -f /inputs/fair-face-volume/fairface
        echo "-------------------------------------- 4 - List outputs"
        cp -R ./outputs/training-output-dataset /outputs
        ls /outputs
        ls -R /outputs/training-output-dataset
      image: tensorflow/tensorflow:2.12.0-gpu
    outputs:
      training-output-dataset:
        type: dataset
        with:
          ref: "dsqbuhm53vosqqs"

  # TrainEightLayersFiveKernelSize:
  #   needs:
  #     - CloneRepo
  #     - GetFairFaceDataset
  #   inputs:
  #     repo: CloneRepo.outputs.repo
  #     fair-face-volume: GetFairFaceDataset.outputs.fair-face-volume
  #   uses: script@v1
  #   with:
  #     script: |-
  #       echo "-------------------------------------- 0 - List Training Data"
  #       ls /inputs/fair-face-volume/fairface/
  #       echo "-------------------------------------- 2 - Access Repo" 
  #       cd /inputs/repo
  #       echo "-------------------------------------- 1 - Setup ENV"
  #       source setup.sh
  #       echo "-------------------------------------- 3 - Run Training"
  #       python ./train.py -e 4 -b 64 -s 3 -c 1 --overwrite_sample_number true --number_samples 100 -m ./layers_8_kernel_5_no_flat.yaml -f /inputs/fair-face-volume/fairface
  #       echo "-------------------------------------- 4 - List outputs"
  #       cp -R ./outputs/training-output-dataset /outputs
  #       ls /outputs
  #       ls -R /outputs/training-output-dataset
  #     image: tensorflow/tensorflow:2.12.0-gpu
  #   outputs:
  #     training-output-dataset:
  #       type: dataset
  #       with:
  #         ref: "dsqbuhm53vosqqs"
# https://docs.digitalocean.com/products/paperspace/workflows/concepts/environment-variables/